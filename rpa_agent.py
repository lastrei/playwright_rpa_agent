import os
import subprocess
import tempfile
import time
from typing import Tuple, Optional
from openai import OpenAI

class Recorder:
    def __init__(self):
        # We use a fixed temporary filename for recording to avoid cluttering /tmp with unique files
        # every time the app is restarted or used.
        self.output_path = os.path.join(tempfile.gettempdir(), "playwright_recording_temp.py")
        # Ensure the directory exists (tempfile.gettempdir() should always exist, but good practice)
        # Note: We do NOT create the file here, only define the path. 
        # Playwright codegen will create/overwrite it, or we create it if we need to mock.

    def start_recording(self, url: str = None):
        """
        Launches playwright codegen.
        On a real machine, this opens a browser window.
        """
        cmd = ["playwright", "codegen", "-o", self.output_path]
        if url:
            cmd.append(url)
        
        # We run this ensuring it doesn't block forever if we were in a script,
        # but for the UI, we might want to wait or manage the process.
        # Since 'codegen' blocks until the window is closed, we can run it synchronously
        # or managed by the UI. For simplicity in this agent, we'll assume synchronous
        # blocking execution is fine for the "Record" action (the UI will freeze until closed, 
        # or we run it in a thread).
        try:
            subprocess.run(cmd, check=True)
        except subprocess.CalledProcessError as e:
            print(f"Error during recording: {e}")
        except FileNotFoundError:
            print("Playwright not found. Is it installed?")

    def get_recorded_code(self) -> str:
        """Reads the captured code from the temporary file."""
        if os.path.exists(self.output_path):
            with open(self.output_path, "r", encoding="utf-8") as f:
                return f.read()
        return ""

class LLMClient:
    def __init__(self, api_key: str, base_url: str, model_name: str):
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.model_name = model_name

    def refine_code(self, user_prompt: str, raw_code: str) -> str:
        """
        Sends the user prompt and raw code to the LLM to generate refined Playwright code.
        """
        system_prompt = (
            "You are an expert Playwright and Python developer. "
            "Your task is to take raw Playwright code generated by 'codegen' and a user's intent, "
            "and convert it into a robust, clean, and executable Python script. "
            "1. Remove unnecessary code (like closing the browser immediately if the task implies continuing). "
            "2. Replace rigid clicks with robust locators or assertions where appropriate. "
            "3. If the user wants to 'extract' or 'get' data, add print statements or return values. "
            "4. Add comments explaining the steps. "
            "5. Ensure the code imports necessary modules (playwright.sync_api, etc.). "
            "6. Return ONLY the python code, no markdown backticks."
        )
        
        user_message = (
            f"User Intent: {user_prompt}\n\n"
            f"Raw Recorded Code:\n{raw_code}\n\n"
            "Please generate the improved Python code."
        )

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
            )
            return self._clean_output(response.choices[0].message.content)
        except Exception as e:
            return f"# Error calling LLM: {str(e)}"

    def fix_code(self, code: str, error_message: str) -> str:
        """
        Sends the broken code and error message to the LLM to fix it.
        """
        system_prompt = (
            "You are an expert Python debugger. "
            "Fix the following Playwright code based on the error message provided. "
            "Return ONLY the fixed python code, no markdown backticks."
        )
        
        user_message = (
            f"Code:\n{code}\n\n"
            f"Error Message:\n{error_message}\n\n"
            "Please fix the code."
        )

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
            )
            return self._clean_output(response.choices[0].message.content)
        except Exception as e:
            return f"# Error calling LLM: {str(e)}"

    def _clean_output(self, text: str) -> str:
        """Removes markdown code blocks if present."""
        text = text.strip()
        if text.startswith("```python"):
            text = text[9:]
        elif text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        return text.strip()

class CodeRunner:
    def __init__(self, script_path: str = "generated_bot.py"):
        self.script_path = script_path

    def run_code(self, code: str) -> Tuple[str, str, bool]:
        """
        Saves the code to a file and runs it.
        Returns (stdout, stderr, success_boolean).
        """
        # Save code
        with open(self.script_path, "w", encoding="utf-8") as f:
            f.write(code)

        # Run code
        try:
            result = subprocess.run(
                ["python", self.script_path],
                capture_output=True,
                text=True,
                timeout=300 # 5 minutes timeout
            )
            return result.stdout, result.stderr, result.returncode == 0
        except subprocess.TimeoutExpired:
            return "", "Execution timed out after 5 minutes.", False
        except Exception as e:
            return "", str(e), False
